{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtered Backprojection Cone Beam Reconstruction\n",
    "## With Configurable Filter Sizes and Types\n",
    "\n",
    "This notebook implements true filtered backprojection for EPID dose reconstruction with:\n",
    "- Configurable filter types (Shepp-Logan, Ram-Lak, Cosine, Hamming)\n",
    "- Adjustable filter sizes (0.1 to 1.0 factor)\n",
    "- Global mask for consistent processing\n",
    "- Comparison between different reconstruction approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CPU cores: 24\n",
      "Numba JIT compilation available\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "from pydicom import dcmread, dcmwrite\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.fft import fft, ifft\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import multiprocessing\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PI = math.pi\n",
    "print(f\"Available CPU cores: {multiprocessing.cpu_count()}\")\n",
    "\n",
    "# Try to import numba for JIT compilation\n",
    "try:\n",
    "    from numba import jit, prange\n",
    "    NUMBA_AVAILABLE = True\n",
    "    print(\"Numba JIT compilation available\")\n",
    "except ImportError:\n",
    "    NUMBA_AVAILABLE = False\n",
    "    print(\"Numba not available - using pure NumPy\")\n",
    "    def jit(func):\n",
    "        return func\n",
    "    prange = range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Visualization and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_SL_broken(N, d):\n",
    "    \"\"\"Original Shepp-Logan filter - BROKEN VERSION\"\"\"\n",
    "    fh_SL = np.zeros(N)\n",
    "    for k1 in range(0, N, 1):\n",
    "        fh_SL[k1] = -2.0/(PI*PI*d*d*(4*(k1-N/2.0)**2-1))\n",
    "        \n",
    "    # This line overwrites everything with zeros! \n",
    "    fh_SL = np.zeros(N)  # ‚ùå THIS IS THE BUG!\n",
    "    return fh_SL\n",
    "\n",
    "def filter_SL(N, d, filter_size_factor=1.0):\n",
    "    \"\"\"FIXED Shepp-Logan filter with configurable size\"\"\"\n",
    "    fh_SL = np.zeros(N)\n",
    "    \n",
    "    # Apply filter size factor to control filter extent\n",
    "    effective_N = int(N * filter_size_factor)\n",
    "    center = N // 2\n",
    "    start_idx = max(0, center - effective_N // 2)\n",
    "    end_idx = min(N, center + effective_N // 2)\n",
    "    \n",
    "    for k1 in range(start_idx, end_idx):\n",
    "        denominator = 4*(k1-N/2.0)**2-1\n",
    "        if abs(denominator) > 1e-10:  # Avoid division by zero\n",
    "            fh_SL[k1] = -2.0/(PI*PI*d*d*denominator)\n",
    "        else:\n",
    "            fh_SL[k1] = 0.0\n",
    "    \n",
    "    return fh_SL\n",
    "\n",
    "def filter_SL_proper(N, d, filter_size_factor=1.0):\n",
    "    \"\"\"Proper Shepp-Logan filter implementation with configurable size\"\"\"\n",
    "    fh_SL = np.zeros(N)\n",
    "    \n",
    "    # Apply filter size factor\n",
    "    effective_N = int(N * filter_size_factor)\n",
    "    center = N // 2\n",
    "    start_idx = max(0, center - effective_N // 2)\n",
    "    end_idx = min(N, center + effective_N // 2)\n",
    "    \n",
    "    for k1 in range(start_idx, end_idx):\n",
    "        if k1 == N//2:\n",
    "            # DC component\n",
    "            fh_SL[k1] = 1.0 / (4.0 * d * d)\n",
    "        elif (k1 - N//2) % 2 != 0:\n",
    "            # Odd frequencies\n",
    "            fh_SL[k1] = -1.0 / (PI * PI * d * d * (k1 - N//2) ** 2)\n",
    "    \n",
    "    return fh_SL\n",
    "\n",
    "def filter_SL_configurable(N, d, filter_type='shepp_logan', filter_size_factor=1.0, cutoff_freq=None):\n",
    "    \"\"\"Configurable filter with multiple types and size control\"\"\"\n",
    "    fh_SL = np.zeros(N)\n",
    "    \n",
    "    # Determine effective filter size\n",
    "    if cutoff_freq is not None:\n",
    "        # Use cutoff frequency to determine filter size\n",
    "        effective_N = min(N, int(2 * cutoff_freq * N / (1.0 / d)))\n",
    "    else:\n",
    "        # Use filter size factor\n",
    "        effective_N = int(N * filter_size_factor)\n",
    "    \n",
    "    center = N // 2\n",
    "    start_idx = max(0, center - effective_N // 2)\n",
    "    end_idx = min(N, center + effective_N // 2)\n",
    "    \n",
    "    if filter_type == 'shepp_logan':\n",
    "        for k1 in range(start_idx, end_idx):\n",
    "            denominator = 4*(k1-N/2.0)**2-1\n",
    "            if abs(denominator) > 1e-10:\n",
    "                fh_SL[k1] = -2.0/(PI*PI*d*d*denominator)\n",
    "    \n",
    "    elif filter_type == 'ram_lak':\n",
    "        # Ramp filter (Ram-Lak)\n",
    "        for k1 in range(start_idx, end_idx):\n",
    "            if k1 == center:\n",
    "                fh_SL[k1] = 1.0 / (4.0 * d * d)\n",
    "            else:\n",
    "                fh_SL[k1] = -1.0 / (PI * PI * d * d * (k1 - center) ** 2)\n",
    "    \n",
    "    elif filter_type == 'cosine':\n",
    "        # Cosine filter\n",
    "        for k1 in range(start_idx, end_idx):\n",
    "            if k1 == center:\n",
    "                fh_SL[k1] = 1.0 / (4.0 * d * d)\n",
    "            else:\n",
    "                freq = (k1 - center) / (N * d)\n",
    "                fh_SL[k1] = -1.0 / (PI * PI * d * d * (k1 - center) ** 2) * np.cos(PI * freq * d)\n",
    "    \n",
    "    elif filter_type == 'hamming':\n",
    "        # Hamming windowed filter\n",
    "        for k1 in range(start_idx, end_idx):\n",
    "            if k1 == center:\n",
    "                fh_SL[k1] = 1.0 / (4.0 * d * d)\n",
    "            else:\n",
    "                # Basic filter\n",
    "                base_filter = -1.0 / (PI * PI * d * d * (k1 - center) ** 2)\n",
    "                # Apply Hamming window\n",
    "                window_val = 0.54 + 0.46 * np.cos(2 * PI * (k1 - center) / effective_N)\n",
    "                fh_SL[k1] = base_filter * window_val\n",
    "    \n",
    "    return fh_SL\n",
    "\n",
    "def nearestPowerOf2(N):\n",
    "    \"\"\"Original power of 2 function\"\"\"\n",
    "    a = int(math.log2(N))\n",
    "    if 2**a == N:\n",
    "        return N\n",
    "    return 2**(a + 1)\n",
    "\n",
    "def Fun_Weigth_Projection(projection_beta, SOD, delta_dd):\n",
    "    \"\"\"Original weighting function\"\"\"\n",
    "    Nrows, Ncolumns = projection_beta.shape\n",
    "    dd_column = delta_dd*np.arange(-Ncolumns/2+0.5, (Ncolumns/2+1)-0.5, 1.0)\n",
    "    dd_row = delta_dd*np.arange(-Nrows/2+0.5, (Nrows/2+1)-0.5, 1.0)\n",
    "    dd_row2D, dd_column2D = np.meshgrid(dd_row, dd_column, indexing='ij')\n",
    "    weighted_projection = projection_beta*SOD/np.sqrt(SOD*SOD+np.power(dd_row2D, 2.0)+np.power(dd_column2D, 2.0))\n",
    "    return weighted_projection\n",
    "\n",
    "def optimize_convolution_configurable(weighted_projection, fh_RL, filter_size_override=None):\n",
    "    \"\"\"Enhanced convolution with optional filter size override\"\"\"\n",
    "    Nrows, Ncolumns = weighted_projection.shape\n",
    "    \n",
    "    if filter_size_override is not None:\n",
    "        Nfft = filter_size_override\n",
    "    else:\n",
    "        Nfft = nearestPowerOf2(2 * Ncolumns - 1)\n",
    "    \n",
    "    # Ensure filter is the right size\n",
    "    if len(fh_RL) != Nfft:\n",
    "        fh_RL_padded = np.zeros(Nfft)\n",
    "        fh_RL_padded[:min(len(fh_RL), Nfft)] = fh_RL[:min(len(fh_RL), Nfft)]\n",
    "        fh_RL = fh_RL_padded\n",
    "    \n",
    "    fh_RL_padded = fh_RL / 2.0\n",
    "    fh_RL_fft = fft(fh_RL_padded)\n",
    "    \n",
    "    projection_padded = np.zeros((Nrows, Nfft))\n",
    "    projection_padded[:, :Ncolumns] = weighted_projection\n",
    "\n",
    "    projection_fft = fft(projection_padded, axis=1)\n",
    "    convoluted_freq = projection_fft * fh_RL_fft\n",
    "    convoluted_time = ifft(convoluted_freq, axis=1).real\n",
    "    filtered_projection = convoluted_time[:, :Ncolumns]\n",
    "    \n",
    "    return filtered_projection\n",
    "\n",
    "# Test different filter configurations\n",
    "print(\"TESTING CONFIGURABLE FILTER IMPLEMENTATIONS:\")\n",
    "test_N = 512\n",
    "test_d = 0.1\n",
    "\n",
    "print(f\"\\nüìä Filter Size Factor Tests (N={test_N}, d={test_d}):\")\n",
    "for factor in [0.25, 0.5, 0.75, 1.0]:\n",
    "    test_filter = filter_SL(test_N, test_d, filter_size_factor=factor)\n",
    "    non_zero = np.count_nonzero(test_filter)\n",
    "    print(f\"  Factor {factor:.2f}: {non_zero} non-zero elements, range: {test_filter.min():.6f} to {test_filter.max():.6f}\")\n",
    "\n",
    "print(f\"\\nüéõÔ∏è Filter Type Tests:\")\n",
    "for ftype in ['shepp_logan', 'ram_lak', 'cosine', 'hamming']:\n",
    "    test_filter = filter_SL_configurable(test_N, test_d, filter_type=ftype, filter_size_factor=0.5)\n",
    "    non_zero = np.count_nonzero(test_filter)\n",
    "    print(f\"  {ftype}: {non_zero} non-zero elements, range: {test_filter.min():.6f} to {test_filter.max():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global mask storage\n",
    "GLOBAL_MASK = None\n",
    "GLOBAL_MASK_INDICES = None\n",
    "\n",
    "def compute_global_mask(SOD, delta_dd, Nimage, Nrows, Ncolumns):\n",
    "    \"\"\"Compute mask once for all projections\"\"\"\n",
    "    MX, MZ = Nimage, int(Nimage*Nrows/Ncolumns)\n",
    "    \n",
    "    roi = delta_dd*np.array([-Ncolumns/2.0+0.5, Ncolumns/2.0-0.5, -Nrows/2.0+0.5, Nrows/2.0-0.5])\n",
    "    hx = (roi[1]-roi[0])/(MX-1)\n",
    "    xrange = roi[0]+hx*np.arange(0, MX)\n",
    "    hy = (roi[3]-roi[2])/(MZ-1)\n",
    "    yrange = roi[2]+hy*np.arange(0, MZ)\n",
    "    XX, YY, ZZ = np.meshgrid(xrange, xrange, yrange, indexing='ij')\n",
    "    \n",
    "    # For any angle, we check the bounds based on the maximum possible extent\n",
    "    # We use a conservative mask that works for all angles\n",
    "    max_extent_x = np.max(np.abs(xrange))\n",
    "    max_extent_y = np.max(np.abs(xrange))\n",
    "    max_extent_z = np.max(np.abs(yrange))\n",
    "    \n",
    "    # Conservative bounds checking\n",
    "    U_min = (SOD - max_extent_x - max_extent_y)/SOD  # Minimum U value\n",
    "    a_max = (max_extent_x + max_extent_y)/U_min  # Maximum a value\n",
    "    b_max = max_extent_z/U_min  # Maximum b value\n",
    "    \n",
    "    xx_max = int(np.floor(a_max/delta_dd)) + int(Ncolumns/2)\n",
    "    yy_max = int(np.floor(b_max/delta_dd)) + int(Nrows/2)\n",
    "    \n",
    "    # Create a conservative mask that ensures indices are always valid\n",
    "    mask_indices = []\n",
    "    for i in range(MX):\n",
    "        for j in range(MX):\n",
    "            for k in range(MZ):\n",
    "                # Conservative check - if any reasonable projection angle could cause out-of-bounds\n",
    "                if (xx_max < Ncolumns-1 and yy_max < Nrows-1):\n",
    "                    mask_indices.append((i, j, k))\n",
    "    \n",
    "    return mask_indices\n",
    "\n",
    "def Fun_BackProjection_with_global_mask(filtered_projection, SOD, beta_num, beta_m, delta_dd, Nimage, use_global_mask=True):\n",
    "    \"\"\"Original backprojection function with optional global mask\"\"\"\n",
    "    global GLOBAL_MASK, GLOBAL_MASK_INDICES\n",
    "    \n",
    "    Nrows, Ncolumns = filtered_projection.shape\n",
    "    MX, MZ = Nimage, int(Nimage*Nrows/Ncolumns)\n",
    "    \n",
    "    roi = delta_dd*np.array([-Ncolumns/2.0+0.5, Ncolumns/2.0-0.5, -Nrows/2.0+0.5, Nrows/2.0-0.5])\n",
    "    hx = (roi[1]-roi[0])/(MX-1)\n",
    "    xrange = roi[0]+hx*np.arange(0, MX)\n",
    "    hy = (roi[3]-roi[2])/(MZ-1)\n",
    "    yrange = roi[2]+hy*np.arange(0, MZ)\n",
    "    XX, YY, ZZ = np.meshgrid(xrange, xrange, yrange, indexing='ij')\n",
    "    temp_rec = np.zeros((MX, MX, MZ))\n",
    "    \n",
    "    U = (SOD+XX*np.sin(beta_m)-YY*np.cos(beta_m))/SOD\n",
    "    a = (XX*np.cos(beta_m)+YY*np.sin(beta_m))/U\n",
    "    xx = np.int32(np.floor(a/delta_dd))\n",
    "    u1 = a/delta_dd-xx\n",
    "    b = ZZ/U\n",
    "    yy = np.int32(np.floor(b/delta_dd))\n",
    "    u2 = b/delta_dd-yy\n",
    "    xx = xx+int(Ncolumns/2)\n",
    "    yy = yy+int(Nrows/2)\n",
    "\n",
    "    if use_global_mask and GLOBAL_MASK is not None:\n",
    "        # Use pre-computed global mask\n",
    "        mask = GLOBAL_MASK\n",
    "    else:\n",
    "        # Compute mask for this projection (original behavior)\n",
    "        mask = np.where((xx >= 0) & (xx < Ncolumns-1) & (yy >= 0) & (yy < Nrows-1))\n",
    "        if not use_global_mask:\n",
    "            print(f\"Mask shape: {len(mask[0])} valid voxels\")\n",
    "    \n",
    "    xx_masked = xx[mask]\n",
    "    yy_masked = yy[mask]\n",
    "    u1_masked = u1[mask]\n",
    "    u2_masked = u2[mask]\n",
    "    \n",
    "    # Ensure indices are within bounds\n",
    "    valid_indices = (xx_masked >= 0) & (xx_masked < Ncolumns-1) & (yy_masked >= 0) & (yy_masked < Nrows-1)\n",
    "    xx_masked = xx_masked[valid_indices]\n",
    "    yy_masked = yy_masked[valid_indices]\n",
    "    u1_masked = u1_masked[valid_indices]\n",
    "    u2_masked = u2_masked[valid_indices]\n",
    "    \n",
    "    if len(xx_masked) > 0:\n",
    "        temp = ((1-u1_masked)*(1-u2_masked)*filtered_projection[yy_masked, xx_masked]+\n",
    "                (1-u1_masked)*u2_masked*filtered_projection[yy_masked+1, xx_masked]+\n",
    "                (1-u2_masked)*u1_masked*filtered_projection[yy_masked, xx_masked+1]+\n",
    "                u1_masked*u2_masked*filtered_projection[yy_masked+1, xx_masked+1])\n",
    "        \n",
    "        # Create a sub-mask for the valid indices\n",
    "        final_mask = tuple(arr[valid_indices] for arr in mask)\n",
    "        temp_rec[final_mask] = temp_rec[final_mask] + temp/(np.power(U[final_mask], 2))*2*PI/beta_num\n",
    "    \n",
    "    return temp_rec\n",
    "\n",
    "# Keep original function for comparison\n",
    "def Fun_BackProjection(filtered_projection, SOD, beta_num, beta_m, delta_dd, Nimage):\n",
    "    \"\"\"Original backprojection function - \"\"\"\n",
    "    return Fun_BackProjection_with_global_mask(filtered_projection, SOD, beta_num, beta_m, delta_dd, Nimage, use_global_mask=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dicom_fast(path_list, max_workers=8):\n",
    "    \"\"\"Fast DICOM loading with threading\"\"\"\n",
    "    def read_dicom_data(fname):\n",
    "        try:\n",
    "            dcm = dcmread(fname)\n",
    "            return dcm.pixel_array.astype(np.uint16), float(dcm.GantryAngle)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {fname}: {e}\")\n",
    "            return None, None\n",
    "    \n",
    "    images = []\n",
    "    angles = []\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        with tqdm(total=len(path_list), desc=\"Loading DICOM files\") as pbar:\n",
    "            future_to_path = {executor.submit(read_dicom_data, path): path for path in path_list}\n",
    "            \n",
    "            for future in future_to_path:\n",
    "                img, angle = future.result()\n",
    "                if img is not None:\n",
    "                    images.append(img)\n",
    "                    angles.append(angle)\n",
    "                pbar.update(1)\n",
    "    \n",
    "    return np.array(images), np.array(angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def process_differential_unrotated(images, angles, threshold=10000):\n",
    "    \"\"\"Revert to unrotated method - exactly as original but without rotation\"\"\"\n",
    "    n_images = len(images)\n",
    "    shape = images[0].shape\n",
    "    processed_images = np.zeros((n_images, shape[0], shape[0]), dtype=np.uint16)\n",
    "    processed_angles = []\n",
    "    \n",
    "    prev = np.zeros((shape[0], shape[0]), dtype=np.uint16)\n",
    "    \n",
    "    for idx in tqdm(range(n_images), desc=\"Processing differences (unrotated)\"):\n",
    "        curr = images[idx]\n",
    "        _m = curr - prev\n",
    "        \n",
    "        if np.max(_m) > threshold:\n",
    "            # Use previous processed image when threshold exceeded (no rotation)\n",
    "            if idx > 0:\n",
    "                processed_images[idx, :, :] = processed_images[idx-1, :, :]\n",
    "                processed_angles.append(processed_angles[idx-1])\n",
    "            else:\n",
    "                processed_images[idx, :, :] = curr - prev\n",
    "                processed_angles.append(angles[idx])\n",
    "        else:\n",
    "            # Normal differential processing\n",
    "            processed_images[idx, :, :] = curr - prev\n",
    "            processed_angles.append(angles[idx])\n",
    "        \n",
    "        # Always update prev\n",
    "        prev = curr\n",
    "    \n",
    "    return processed_images, np.array(processed_angles)\n",
    "\n",
    "# Let's examine a DICOM file to understand the metadata\n",
    "def examine_dicom_metadata(dicom_path):\n",
    "    \"\"\"Examine DICOM metadata thoroughly\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(f\"EXAMINING DICOM METADATA: {dicom_path}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    dcm = dcmread(dicom_path)\n",
    "    \n",
    "    # Core imaging parameters\n",
    "    print(\"\\nüìä CORE IMAGING PARAMETERS:\")\n",
    "    print(f\"  Modality: {getattr(dcm, 'Modality', 'N/A')}\")\n",
    "    print(f\"  RT Image Label: {getattr(dcm, 'RTImageLabel', 'N/A')}\")\n",
    "    print(f\"  RT Image Plane: {getattr(dcm, 'RTImagePlane', 'N/A')}\")\n",
    "    print(f\"  RT Image Position: {getattr(dcm, 'RTImagePosition', 'N/A')}\")\n",
    "    print(f\"  RT Image Orientation: {getattr(dcm, 'RTImageOrientation', 'N/A')}\")\n",
    "    \n",
    "    # Geometry parameters\n",
    "    print(\"\\nüìê GEOMETRY PARAMETERS:\")\n",
    "    print(f\"  RT Image SID: {getattr(dcm, 'RTImageSID', 'N/A')}\")\n",
    "    print(f\"  Radiation Machine SAD: {getattr(dcm, 'RadiationMachineSAD', 'N/A')}\")\n",
    "    print(f\"  Gantry Angle: {getattr(dcm, 'GantryAngle', 'N/A')}\")\n",
    "    print(f\"  Patient Support Angle: {getattr(dcm, 'PatientSupportAngle', 'N/A')}\")\n",
    "    print(f\"  Table Top Eccentric Angle: {getattr(dcm, 'TableTopEccentricAngle', 'N/A')}\")\n",
    "    \n",
    "    # Image parameters\n",
    "    print(\"\\nüñºÔ∏è IMAGE PARAMETERS:\")\n",
    "    print(f\"  Rows: {getattr(dcm, 'Rows', 'N/A')}\")\n",
    "    print(f\"  Columns: {getattr(dcm, 'Columns', 'N/A')}\")\n",
    "    print(f\"  Pixel Spacing: {getattr(dcm, 'PixelSpacing', 'N/A')}\")\n",
    "    print(f\"  Image Plane Pixel Spacing: {getattr(dcm, 'ImagePlanePixelSpacing', 'N/A')}\")\n",
    "    print(f\"  Bits Allocated: {getattr(dcm, 'BitsAllocated', 'N/A')}\")\n",
    "    print(f\"  Bits Stored: {getattr(dcm, 'BitsStored', 'N/A')}\")\n",
    "    print(f\"  Pixel Representation: {getattr(dcm, 'PixelRepresentation', 'N/A')}\")\n",
    "    \n",
    "    # Dose/calibration parameters\n",
    "    print(\"\\n‚ö° DOSE/CALIBRATION PARAMETERS:\")\n",
    "    print(f\"  Primary Dosimeter Unit: {getattr(dcm, 'PrimaryDosimeterUnit', 'N/A')}\")\n",
    "    print(f\"  RT Image Description: {getattr(dcm, 'RTImageDescription', 'N/A')}\")\n",
    "    print(f\"  Exposure: {getattr(dcm, 'Exposure', 'N/A')}\")\n",
    "    print(f\"  X-Ray Tube Current: {getattr(dcm, 'XRayTubeCurrent', 'N/A')}\")\n",
    "    print(f\"  KVP: {getattr(dcm, 'KVP', 'N/A')}\")\n",
    "    \n",
    "    # Image position/orientation in 3D space\n",
    "    print(\"\\nüåê 3D POSITIONING:\")\n",
    "    print(f\"  Image Position Patient: {getattr(dcm, 'ImagePositionPatient', 'N/A')}\")\n",
    "    print(f\"  Image Orientation Patient: {getattr(dcm, 'ImageOrientationPatient', 'N/A')}\")\n",
    "    \n",
    "    # Acquisition parameters\n",
    "    print(\"\\nüéØ ACQUISITION PARAMETERS:\")\n",
    "    print(f\"  Acquisition Date: {getattr(dcm, 'AcquisitionDate', 'N/A')}\")\n",
    "    print(f\"  Acquisition Time: {getattr(dcm, 'AcquisitionTime', 'N/A')}\")\n",
    "    print(f\"  Instance Number: {getattr(dcm, 'InstanceNumber', 'N/A')}\")\n",
    "    print(f\"  Series Number: {getattr(dcm, 'SeriesNumber', 'N/A')}\")\n",
    "    \n",
    "    # Check pixel data\n",
    "    print(\"\\nüíæ PIXEL DATA:\")\n",
    "    pixel_array = dcm.pixel_array\n",
    "    print(f\"  Pixel array shape: {pixel_array.shape}\")\n",
    "    print(f\"  Pixel array dtype: {pixel_array.dtype}\")\n",
    "    print(f\"  Value range: {pixel_array.min()} to {pixel_array.max()}\")\n",
    "    print(f\"  Mean value: {pixel_array.mean():.2f}\")\n",
    "    \n",
    "    return dcm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilteredBackprojectionReconstructor:\n",
    "    \"\"\"True Filtered Backprojection reconstructor with configurable filters\"\"\"\n",
    "    \n",
    "    def __init__(self, SOD, delta_dd, Nimage):\n",
    "        self.SOD = SOD\n",
    "        self.delta_dd = delta_dd\n",
    "        self.Nimage = Nimage\n",
    "        self.global_mask_initialized = False\n",
    "    \n",
    "    def initialize_global_mask(self, projections):\n",
    "        \"\"\"Initialize the global mask once for all projections\"\"\"\n",
    "        global GLOBAL_MASK\n",
    "        \n",
    "        Nrows, Ncolumns = projections.shape[1], projections.shape[2]\n",
    "        MX, MZ = self.Nimage, int(self.Nimage * Nrows / Ncolumns)\n",
    "        \n",
    "        # Create coordinate grids once\n",
    "        roi = self.delta_dd*np.array([-Ncolumns/2.0+0.5, Ncolumns/2.0-0.5, -Nrows/2.0+0.5, Nrows/2.0-0.5])\n",
    "        hx = (roi[1]-roi[0])/(MX-1)\n",
    "        xrange = roi[0]+hx*np.arange(0, MX)\n",
    "        hy = (roi[3]-roi[2])/(MZ-1)\n",
    "        yrange = roi[2]+hy*np.arange(0, MZ)\n",
    "        XX, YY, ZZ = np.meshgrid(xrange, xrange, yrange, indexing='ij')\n",
    "        \n",
    "        # Compute a conservative mask that works for most projections\n",
    "        U = (self.SOD + XX*np.sin(0) - YY*np.cos(0))/self.SOD\n",
    "        a = (XX*np.cos(0) + YY*np.sin(0))/U\n",
    "        xx = np.int32(np.floor(a/self.delta_dd))\n",
    "        b = ZZ/U\n",
    "        yy = np.int32(np.floor(b/self.delta_dd))\n",
    "        xx = xx + int(Ncolumns/2)\n",
    "        yy = yy + int(Nrows/2)\n",
    "        \n",
    "        # Create a slightly more conservative mask\n",
    "        margin = 5  # pixels margin for safety\n",
    "        GLOBAL_MASK = np.where((xx >= margin) & (xx < Ncolumns-1-margin) & \n",
    "                              (yy >= margin) & (yy < Nrows-1-margin))\n",
    "        \n",
    "        self.global_mask_initialized = True\n",
    "        print(f\"Global mask initialized with {len(GLOBAL_MASK[0])} valid voxels\")\n",
    "        return GLOBAL_MASK\n",
    "    \n",
    "    def reconstruct_filtered_backprojection(self, projections, angles, \n",
    "                                          filter_type='shepp_logan',\n",
    "                                          filter_size_factor=1.0,\n",
    "                                          use_weighting=True,\n",
    "                                          chunk_size=25, \n",
    "                                          use_global_mask=True):\n",
    "        \"\"\"\n",
    "        True Filtered Backprojection reconstruction\n",
    "        \n",
    "        Parameters:\n",
    "        - filter_type: 'shepp_logan', 'ram_lak', 'cosine', 'hamming'\n",
    "        - filter_size_factor: 0.1 to 1.0 (controls filter extent)\n",
    "        - use_weighting: Whether to apply geometric weighting before filtering\n",
    "        \"\"\"\n",
    "        n_angles = len(angles)\n",
    "        beta_rad = angles * PI / 180.0\n",
    "        \n",
    "        # Initialize global mask if requested\n",
    "        if use_global_mask and not self.global_mask_initialized:\n",
    "            self.initialize_global_mask(projections)\n",
    "        \n",
    "        # Prepare configurable filter\n",
    "        Ncolumns = projections.shape[2]\n",
    "        Nrows = projections.shape[1]\n",
    "        Nfft = nearestPowerOf2(2 * Ncolumns - 1)\n",
    "        \n",
    "        fh_RL = filter_SL_configurable(\n",
    "            Nfft, \n",
    "            self.delta_dd, \n",
    "            filter_type=filter_type, \n",
    "            filter_size_factor=filter_size_factor\n",
    "        )\n",
    "        \n",
    "        print(f\"FILTERED BACKPROJECTION RECONSTRUCTION:\")\n",
    "        print(f\"  Projections: {n_angles}\")\n",
    "        print(f\"  Filter type: {filter_type}\")\n",
    "        print(f\"  Filter size factor: {filter_size_factor}\")\n",
    "        print(f\"  Filter size: {len(fh_RL)}, Nfft: {Nfft}\")\n",
    "        print(f\"  Filter non-zero elements: {np.count_nonzero(fh_RL)}\")\n",
    "        print(f\"  Filter range: {fh_RL.min():.6f} to {fh_RL.max():.6f}\")\n",
    "        print(f\"  Use weighting: {use_weighting}\")\n",
    "        print(f\"  Use global mask: {use_global_mask}\")\n",
    "        \n",
    "        # Initialize result\n",
    "        MX = self.Nimage\n",
    "        MZ = int(self.Nimage * Nrows / Ncolumns)\n",
    "        rec_image = np.zeros((MX, MX, MZ))\n",
    "        \n",
    "        # Process in chunks\n",
    "        chunks = [list(range(i, min(i + chunk_size, n_angles))) \n",
    "                 for i in range(0, n_angles, chunk_size)]\n",
    "        \n",
    "        print(f\"  Processing in {len(chunks)} chunks...\")\n",
    "        \n",
    "        for chunk_idx, chunk_indices in enumerate(tqdm(chunks, desc=\"Filtered backprojection\")):\n",
    "            chunk_result = np.zeros((MX, MX, MZ))\n",
    "            \n",
    "            for i, angle_idx in enumerate(chunk_indices):\n",
    "                projection_beta = projections[angle_idx, :, :]\n",
    "                \n",
    "                # Step 1: Optional geometric weighting\n",
    "                if use_weighting:\n",
    "                    weighted_projection = Fun_Weigth_Projection(projection_beta, self.SOD, self.delta_dd)\n",
    "                    input_projection = weighted_projection\n",
    "                else:\n",
    "                    input_projection = projection_beta\n",
    "                \n",
    "                # Step 2: Filter the projection\n",
    "                filtered_projection = optimize_convolution_configurable(input_projection, fh_RL)\n",
    "                \n",
    "                # Step 3: TRUE FILTERED BACKPROJECTION - backproject the filtered data\n",
    "                if use_global_mask:\n",
    "                    temp_rec = Fun_BackProjection_with_global_mask(\n",
    "                        filtered_projection,  # ‚úÖ NOW USING FILTERED PROJECTION!\n",
    "                        self.SOD, \n",
    "                        n_angles,\n",
    "                        beta_rad[angle_idx],\n",
    "                        self.delta_dd, \n",
    "                        self.Nimage,\n",
    "                        use_global_mask=True\n",
    "                    )\n",
    "                else:\n",
    "                    temp_rec = Fun_BackProjection(\n",
    "                        filtered_projection,  # ‚úÖ NOW USING FILTERED PROJECTION!\n",
    "                        self.SOD, \n",
    "                        n_angles,\n",
    "                        beta_rad[angle_idx],\n",
    "                        self.delta_dd, \n",
    "                        self.Nimage\n",
    "                    )\n",
    "                \n",
    "                chunk_result += temp_rec\n",
    "            \n",
    "            rec_image += chunk_result\n",
    "        \n",
    "        return rec_image\n",
    "\n",
    "# For comparison - the old FDK approach\n",
    "class FDKReconstructor(FilteredBackprojectionReconstructor):\n",
    "    \"\"\"Original FDK approach for comparison\"\"\"\n",
    "    \n",
    "    def reconstruct_fdk(self, projections, angles, \n",
    "                       filter_type='shepp_logan',\n",
    "                       filter_size_factor=1.0,\n",
    "                       chunk_size=25, \n",
    "                       use_global_mask=True):\n",
    "        \"\"\"Original FDK reconstruction (backprojects weighted, not filtered)\"\"\"\n",
    "        n_angles = len(angles)\n",
    "        beta_rad = angles * PI / 180.0\n",
    "        \n",
    "        if use_global_mask and not self.global_mask_initialized:\n",
    "            self.initialize_global_mask(projections)\n",
    "        \n",
    "        Ncolumns = projections.shape[2]\n",
    "        Nrows = projections.shape[1]\n",
    "        Nfft = nearestPowerOf2(2 * Ncolumns - 1)\n",
    "        \n",
    "        fh_RL = filter_SL_configurable(\n",
    "            Nfft, self.delta_dd, \n",
    "            filter_type=filter_type, \n",
    "            filter_size_factor=filter_size_factor\n",
    "        )\n",
    "        \n",
    "        print(f\"FDK RECONSTRUCTION (for comparison):\")\n",
    "        print(f\"  Filter type: {filter_type}, size factor: {filter_size_factor}\")\n",
    "        \n",
    "        MX = self.Nimage\n",
    "        MZ = int(self.Nimage * Nrows / Ncolumns)\n",
    "        rec_image = np.zeros((MX, MX, MZ))\n",
    "        \n",
    "        chunks = [list(range(i, min(i + chunk_size, n_angles))) \n",
    "                 for i in range(0, n_angles, chunk_size)]\n",
    "        \n",
    "        for chunk_idx, chunk_indices in enumerate(tqdm(chunks, desc=\"FDK reconstruction\")):\n",
    "            chunk_result = np.zeros((MX, MX, MZ))\n",
    "            \n",
    "            for angle_idx in chunk_indices:\n",
    "                projection_beta = projections[angle_idx, :, :]\n",
    "                \n",
    "                # Weight and filter\n",
    "                weighted_projection = Fun_Weigth_Projection(projection_beta, self.SOD, self.delta_dd)\n",
    "                filtered_projection = optimize_convolution_configurable(weighted_projection, fh_RL)\n",
    "                \n",
    "                # FDK: backproject the weighted (not filtered) projection\n",
    "                if use_global_mask:\n",
    "                    temp_rec = Fun_BackProjection_with_global_mask(\n",
    "                        weighted_projection,  # ‚ùó FDK uses weighted, not filtered\n",
    "                        self.SOD, n_angles, beta_rad[angle_idx], \n",
    "                        self.delta_dd, self.Nimage, use_global_mask=True\n",
    "                    )\n",
    "                else:\n",
    "                    temp_rec = Fun_BackProjection(\n",
    "                        weighted_projection,  # ‚ùó FDK uses weighted, not filtered\n",
    "                        self.SOD, n_angles, beta_rad[angle_idx], \n",
    "                        self.delta_dd, self.Nimage\n",
    "                    )\n",
    "                \n",
    "                chunk_result += temp_rec\n",
    "            \n",
    "            rec_image += chunk_result\n",
    "        \n",
    "        return rec_image\n",
    "\n",
    "print(\"‚úÖ Filtered Backprojection Reconstructor ready!\")\n",
    "print(\"   - True filtered backprojection: backprojects the filtered projection\")\n",
    "print(\"   - Configurable filters: shepp_logan, ram_lak, cosine, hamming\") \n",
    "print(\"   - Adjustable filter size: factor 0.1 to 1.0\")\n",
    "print(\"   - Optional geometric weighting\")\n",
    "print(\"   - Global mask for consistency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 415 DICOM files from SIB COMPLEX TARGET dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading DICOM files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 415/415 [00:00<00:00, 435.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DICOM loading: 1.74s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing differences:  22%|‚ñà‚ñà‚ñè       | 93/415 [00:00<00:01, 208.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 73/415 with angle 239.71469642569 degrees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing differences:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 172/415 [00:00<00:01, 224.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 152/415 with angle 308.736590321357 degrees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing differences:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 369/415 [00:01<00:00, 287.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 325/415 with angle 105.146962089456 degrees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing differences: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 415/415 [00:01<00:00, 248.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differential processing: 1.67s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Data path - single folder for SIB COMPLEX TARGET\n",
    "_data_pth = r\"E:\\CMC\\pyprojects\\radio_therapy\\dose-3d\\dataset\\VMAT 2025 - 6. SIB COMPLEX TARGET\\T1\\873251691\"\n",
    "\n",
    "# Get all DICOM files from the single folder\n",
    "_files = [f for f in os.listdir(_data_pth) if f.endswith('.dcm')]\n",
    "_pth = [os.path.join(_data_pth, f) for f in _files]\n",
    "\n",
    "print(f\"Processing {len(_pth)} DICOM files from SIB COMPLEX TARGET dataset\")\n",
    "\n",
    "# Load and process data with original algorithm\n",
    "start_time = time.time()\n",
    "raw_images, raw_angles = load_dicom_fast(_pth, max_workers=6)\n",
    "print(f\"DICOM loading: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "start_time = time.time()\n",
    "processed_images, processed_angles = process_differential_original(raw_images, raw_angles)\n",
    "print(f\"Differential processing: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "# # Sort by angle - EXACTLY as original\n",
    "# sorted_indices = np.argsort(processed_angles)\n",
    "# sorted_images = np.zeros((len(_pth), processed_images.shape[1], processed_images.shape[1]), dtype=np.uint16)\n",
    "\n",
    "# for idx, val in enumerate(tqdm(sorted_indices, desc=\"Sorting by angle\")):\n",
    "#     sorted_images[idx, :, :] = processed_images[val, :, :]\n",
    "\n",
    "# sorted_angles = processed_angles[sorted_indices]\n",
    "\n",
    "# print(f\"Final data shape: {sorted_images.shape}\")\n",
    "# print(f\"Angle range: {sorted_angles.min():.1f}¬∞ to {sorted_angles.max():.1f}¬∞\")\n",
    "# print(f\"Data type: {sorted_images.dtype}\")\n",
    "\n",
    "# Clean up memory\n",
    "# del raw_images, processed_images\n",
    "\n",
    "sorted_images = processed_images\n",
    "sorted_angles = processed_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMINE DICOM METADATA AND REVERT TO UNROTATED PROCESSING\n",
    "print(\"=\"*70)\n",
    "print(\"REVERTING TO UNROTATED METHOD AND EXAMINING DICOM METADATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# First, examine a DICOM file to understand what we might be missing\n",
    "sample_dicom_path = _pth[0]  # First DICOM file\n",
    "sample_dcm = examine_dicom_metadata(sample_dicom_path)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"REPROCESSING WITH UNROTATED METHOD\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Reprocess with unrotated method\n",
    "unrotated_images, unrotated_angles = process_differential_unrotated(\n",
    "    raw_images, raw_angles, \n",
    "    threshold=10000\n",
    ")\n",
    "\n",
    "# Sort by angle\n",
    "sorted_indices_unrot = np.argsort(unrotated_angles)\n",
    "sorted_images_unrot = unrotated_images[sorted_indices_unrot]\n",
    "sorted_angles_unrot = unrotated_angles[sorted_indices_unrot]\n",
    "\n",
    "print(f\"\\nUnrotated processing results:\")\n",
    "print(f\"  Total images: {len(sorted_images_unrot)}\")\n",
    "print(f\"  Angle range: {sorted_angles_unrot.min():.1f}¬∞ to {sorted_angles_unrot.max():.1f}¬∞\")\n",
    "\n",
    "# Analyze for issues\n",
    "duplicates = analyze_processed_data(sorted_images_unrot, sorted_angles_unrot)\n",
    "\n",
    "# Compare reconstruction parameters with what the GUI uses\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"COMPARING RECONSTRUCTION PARAMETERS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# From GUI code\n",
    "gui_width = 0.172  # mm (hardcoded in GUI)\n",
    "gui_delta_dd = gui_width * sample_dcm.RadiationMachineSAD / sample_dcm.RTImageSID\n",
    "\n",
    "# From DICOM\n",
    "dicom_pixel_spacing = getattr(sample_dcm, 'ImagePlanePixelSpacing', None)\n",
    "if dicom_pixel_spacing is None:\n",
    "    dicom_pixel_spacing = getattr(sample_dcm, 'PixelSpacing', None)\n",
    "\n",
    "print(f\"GUI approach:\")\n",
    "print(f\"  Width: {gui_width} mm (hardcoded)\")\n",
    "print(f\"  SAD: {sample_dcm.RadiationMachineSAD} mm\")\n",
    "print(f\"  SID: {sample_dcm.RTImageSID} mm\") \n",
    "print(f\"  Delta_dd: {gui_delta_dd:.6f} mm\")\n",
    "\n",
    "print(f\"\\nDICOM metadata approach:\")\n",
    "print(f\"  Pixel spacing from DICOM: {dicom_pixel_spacing}\")\n",
    "if dicom_pixel_spacing:\n",
    "    dicom_delta_dd = float(dicom_pixel_spacing[0]) * sample_dcm.RadiationMachineSAD / sample_dcm.RTImageSID\n",
    "    print(f\"  Calculated delta_dd: {dicom_delta_dd:.6f} mm\")\n",
    "    print(f\"  Difference: {abs(gui_delta_dd - dicom_delta_dd):.6f} mm\")\n",
    "\n",
    "# Set the final data for reconstruction\n",
    "sorted_images = sorted_images_unrot\n",
    "sorted_angles = sorted_angles_unrot\n",
    "\n",
    "print(f\"\\n‚úÖ Reverted to unrotated processing method\")\n",
    "print(f\"üìä Data ready for reconstruction: {len(sorted_images)} images\")\n",
    "\n",
    "# STOP_HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Visualization\n",
    "\n",
    "# Create visualization of different filter types and sizes\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "fig.suptitle('Reconstruction Filter Comparison', fontsize=16)\n",
    "\n",
    "# Test parameters\n",
    "test_N = 512\n",
    "test_d = 0.1\n",
    "x_axis = np.arange(test_N) - test_N//2\n",
    "\n",
    "# Filter types and sizes to test\n",
    "filter_configs = [\n",
    "    ('shepp_logan', 1.0), ('shepp_logan', 0.5), ('shepp_logan', 0.25),\n",
    "    ('ram_lak', 0.5), ('cosine', 0.5), ('hamming', 0.5),\n",
    "    ('shepp_logan', 0.1), ('ram_lak', 0.25)\n",
    "]\n",
    "\n",
    "for i, (filter_type, size_factor) in enumerate(filter_configs):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    \n",
    "    if row < 2 and col < 4:  # Only plot if within subplot grid\n",
    "        # Generate filter\n",
    "        test_filter = filter_SL_configurable(test_N, test_d, \n",
    "                                           filter_type=filter_type, \n",
    "                                           filter_size_factor=size_factor)\n",
    "        \n",
    "        # Plot filter\n",
    "        axes[row, col].plot(x_axis, test_filter, 'b-', linewidth=1.5)\n",
    "        axes[row, col].set_title(f'{filter_type}\\nSize: {size_factor}', fontsize=10)\n",
    "        axes[row, col].grid(True, alpha=0.3)\n",
    "        axes[row, col].set_xlim(-test_N//4, test_N//4)\n",
    "        \n",
    "        # Set y-axis limits for better visualization\n",
    "        if np.any(test_filter != 0):\n",
    "            y_max = np.max(np.abs(test_filter[test_filter != 0]))\n",
    "            axes[row, col].set_ylim(-y_max*1.1, y_max*1.1)\n",
    "        \n",
    "        # Add statistics text\n",
    "        non_zero = np.count_nonzero(test_filter)\n",
    "        axes[row, col].text(0.02, 0.98, f'Non-zero: {non_zero}', \n",
    "                          transform=axes[row, col].transAxes, \n",
    "                          verticalalignment='top', fontsize=8,\n",
    "                          bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "# Remove empty subplots\n",
    "for i in range(len(filter_configs), 8):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    if row < 2 and col < 4:\n",
    "        fig.delaxes(axes[row, col])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary of filter characteristics\n",
    "print(\"FILTER CHARACTERISTICS SUMMARY:\")\n",
    "print(\"=\"*50)\n",
    "print(\"Filter Type    | Size Factor | Non-zero Elements | Max Value\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "for filter_type, size_factor in filter_configs:\n",
    "    test_filter = filter_SL_configurable(test_N, test_d, \n",
    "                                       filter_type=filter_type, \n",
    "                                       filter_size_factor=size_factor)\n",
    "    non_zero = np.count_nonzero(test_filter)\n",
    "    max_val = np.max(np.abs(test_filter)) if np.any(test_filter != 0) else 0\n",
    "    \n",
    "    print(f\"{filter_type:<13} | {size_factor:<11} | {non_zero:<17} | {max_val:.6f}\")\n",
    "\n",
    "print(\"\\nFILTER RECOMMENDATIONS:\")\n",
    "print(\"‚Ä¢ Shepp-Logan: Good general purpose filter\")\n",
    "print(\"‚Ä¢ Ram-Lak: Sharp, high-frequency preservation\")  \n",
    "print(\"‚Ä¢ Cosine: Smoother than Ram-Lak, less noise\")\n",
    "print(\"‚Ä¢ Hamming: Smoothest, best noise reduction\")\n",
    "print(\"‚Ä¢ Smaller size factors: Less noise, smoother images\")\n",
    "print(\"‚Ä¢ Larger size factors: More detail, potentially more noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTERED BACKPROJECTION WITH CONFIGURABLE FILTER SIZES\n",
    "print(\"=\"*70)\n",
    "print(\"TRUE FILTERED BACKPROJECTION WITH CONFIGURABLE FILTERS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get reconstruction parameters\n",
    "dcm = dcmread(_pth[0])\n",
    "SID = dcm.RTImageSID\n",
    "SAD = dcm.RadiationMachineSAD\n",
    "SOD = SAD\n",
    "SDD = SID\n",
    "width = 0.172  # mm\n",
    "delta_dd = width * SOD / SDD\n",
    "Nimage = 100\n",
    "\n",
    "print(f\"Reconstruction parameters:\")\n",
    "print(f\"  Image size: {Nimage}x{Nimage}\")\n",
    "print(f\"  SOD: {SOD} mm, SDD: {SDD} mm, Delta_dd: {delta_dd:.6f} mm\")\n",
    "print(f\"  Using unrotated processed data: {len(sorted_angles)} projections\")\n",
    "\n",
    "# Create filtered backprojection reconstructor\n",
    "fbp_reconstructor = FilteredBackprojectionReconstructor(SOD, delta_dd, Nimage)\n",
    "\n",
    "# Test different filter configurations\n",
    "test_configs = [\n",
    "    {'filter_type': 'shepp_logan', 'filter_size_factor': 0.5, 'use_weighting': True},\n",
    "    {'filter_type': 'shepp_logan', 'filter_size_factor': 0.25, 'use_weighting': True},\n",
    "    {'filter_type': 'ram_lak', 'filter_size_factor': 0.5, 'use_weighting': True},\n",
    "    {'filter_type': 'hamming', 'filter_size_factor': 0.5, 'use_weighting': True},\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for i, config in enumerate(test_configs):\n",
    "    print(f\"\\nüîß TEST {i+1}: {config}\")\n",
    "    print(f\"=\"*50)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    rec_image = fbp_reconstructor.reconstruct_filtered_backprojection(\n",
    "        sorted_images, sorted_angles,\n",
    "        filter_type=config['filter_type'],\n",
    "        filter_size_factor=config['filter_size_factor'],\n",
    "        use_weighting=config['use_weighting'],\n",
    "        chunk_size=25,\n",
    "        use_global_mask=True\n",
    "    )\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate quality metrics\n",
    "    non_zero_voxels = np.count_nonzero(rec_image)\n",
    "    total_voxels = rec_image.size\n",
    "    coverage = non_zero_voxels / total_voxels * 100\n",
    "    \n",
    "    config_name = f\"{config['filter_type']}_f{config['filter_size_factor']}\"\n",
    "    results[config_name] = {\n",
    "        'image': rec_image,\n",
    "        'time': total_time,\n",
    "        'coverage': coverage,\n",
    "        'min_val': rec_image.min(),\n",
    "        'max_val': rec_image.max(),\n",
    "        'mean_nonzero': rec_image[rec_image > 0].mean() if np.any(rec_image > 0) else 0,\n",
    "        'config': config\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nResults for {config_name}:\")\n",
    "    print(f\"  Time: {total_time:.2f} seconds\")\n",
    "    print(f\"  Shape: {rec_image.shape}\")\n",
    "    print(f\"  Value range: {rec_image.min():.6f} to {rec_image.max():.6f}\")\n",
    "    print(f\"  Coverage: {coverage:.1f}% ({non_zero_voxels}/{total_voxels})\")\n",
    "    print(f\"  Mean (non-zero): {rec_image[rec_image > 0].mean():.6f}\" if np.any(rec_image > 0) else \"  No non-zero values\")\n",
    "    print(f\"  Center voxel: {rec_image[50, 50, 50]:.6f}\")\n",
    "\n",
    "# Summary comparison\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY COMPARISON OF FILTERED BACKPROJECTION CONFIGURATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"{'Config':<20} {'Time(s)':<8} {'Coverage(%)':<12} {'Max Value':<12} {'Mean(>0)':<12}\")\n",
    "print(f\"{'-'*20} {'-'*8} {'-'*12} {'-'*12} {'-'*12}\")\n",
    "\n",
    "for name, result in results.items():\n",
    "    print(f\"{name:<20} {result['time']:<8.1f} {result['coverage']:<12.1f} {result['max_val']:<12.6f} {result['mean_nonzero']:<12.6f}\")\n",
    "\n",
    "# Store the best result for visualization\n",
    "best_config = max(results.keys(), key=lambda k: results[k]['coverage'])\n",
    "rec_image = results[best_config]['image']\n",
    "\n",
    "print(f\"\\nüèÜ Best configuration: {best_config}\")\n",
    "print(f\"   Filter: {results[best_config]['config']['filter_type']}\")\n",
    "print(f\"   Size factor: {results[best_config]['config']['filter_size_factor']}\")\n",
    "print(f\"   Coverage: {results[best_config]['coverage']:.1f}%\")\n",
    "\n",
    "print(f\"\\nüí° FILTER SIZE RECOMMENDATIONS:\")\n",
    "print(f\"   ‚Ä¢ Smaller filter (0.25): Less noise, smoother, may lose details\")\n",
    "print(f\"   ‚Ä¢ Medium filter (0.5): Good balance of detail and noise\")\n",
    "print(f\"   ‚Ä¢ Larger filter (1.0): More detail, potentially more noise\")\n",
    "print(f\"   ‚Ä¢ Try different filter types for varying characteristics\")\n",
    "\n",
    "print(f\"\\n‚úÖ True Filtered Backprojection reconstruction complete!\")\n",
    "print(f\"   You can now adjust filter_size_factor from 0.1 to 1.0 for different results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Reconstruction Results\n",
    "\n",
    "# Display reconstruction - cross sections\n",
    "NimageZ = Nimage * sorted_images.shape[1] // sorted_images.shape[2]\n",
    "Z_c = int(NimageZ // 2)\n",
    "X_c = int(Nimage // 2)\n",
    "Y_c = int(Nimage // 2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "fig.suptitle('Filtered Backprojection Reconstruction Results', fontsize=14)\n",
    "\n",
    "# Cross sections\n",
    "axes[0].imshow(rec_image[30, :, :].T, cmap='hot', origin='lower')\n",
    "axes[0].set_title('YZ cross section (X=30)')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(rec_image[:, Y_c, :].T, cmap='hot', origin='lower')\n",
    "axes[1].set_title(f'XZ cross section (Y={Y_c})')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(rec_image[:, :, Z_c].T, cmap='hot', origin='lower')\n",
    "axes[2].set_title(f'XY cross section (Z={Z_c})')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal Reconstruction Statistics:\")\n",
    "print(f\"Min: {rec_image.min():.6f}\")\n",
    "print(f\"Max: {rec_image.max():.6f}\")\n",
    "print(f\"Mean: {rec_image.mean():.6f}\")\n",
    "print(f\"Std: {rec_image.std():.6f}\")\n",
    "print(f\"Non-zero voxels: {np.count_nonzero(rec_image)} / {rec_image.size}\")\n",
    "print(f\"Coverage: {np.count_nonzero(rec_image)/rec_image.size*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "_TPS_pth = r\"E:\\CMC\\pyprojects\\radio_therapy\\dose-3d\\dataset\\3DDose\\EPID_12_t0.dcm\"\n",
    "\n",
    "try:\n",
    "    if os.path.exists(_TPS_pth):\n",
    "        tps_dcm = dcmread(_TPS_pth)\n",
    "        \n",
    "        # Scale and prepare for DICOM export\n",
    "        scaled_image = np.int32(rec_image * 1)\n",
    "        \n",
    "        # Create new DICOM based on TPS template\n",
    "        write_dicom = tps_dcm.copy()\n",
    "        write_dicom.NumberOfFrames = str(rec_image.shape[2])\n",
    "        write_dicom.Rows = rec_image.shape[0]\n",
    "        write_dicom.Columns = rec_image.shape[1]\n",
    "        write_dicom.PixelData = scaled_image.tobytes()\n",
    "        \n",
    "        # Save with timestamp\n",
    "        import datetime\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_path = f\"E:\\\\CMC\\\\pyprojects\\\\radio_therapy\\\\dose-3d\\\\results\\\\filtered_backprojection_{timestamp}.dcm\"\n",
    "        \n",
    "        # Ensure results directory exists\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        \n",
    "        # Uncomment to save:\n",
    "        # dcmwrite(output_path, write_dicom)\n",
    "        print(f\"Ready to save to: {output_path}\")\n",
    "    else:\n",
    "        print(\"TPS template not found - cannot create DICOM output\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error preparing DICOM output: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ Filtered Backprojection reconstruction complete!\")\n",
    "print(\"   You can now experiment with different filter types and sizes:\")\n",
    "print(\"   - Adjust filter_size_factor (0.1 to 1.0)\")\n",
    "print(\"   - Try different filter_type ('shepp_logan', 'ram_lak', 'cosine', 'hamming')\")\n",
    "print(\"   - Toggle use_weighting (True/False)\")\n",
    "print(\"   - Compare with FDK approach if needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Quick Reconstruction Function\n",
    "\n",
    "def quick_reconstruction(filter_type='shepp_logan', filter_size_factor=0.5, use_weighting=True):\n",
    "    \"\"\"Quick function to test different filter configurations\"\"\"\n",
    "    \n",
    "    print(f\"Running reconstruction with:\")\n",
    "    print(f\"  Filter: {filter_type}\")\n",
    "    print(f\"  Size factor: {filter_size_factor}\")\n",
    "    print(f\"  Weighting: {use_weighting}\")\n",
    "    \n",
    "    fbp_reconstructor = FilteredBackprojectionReconstructor(SOD, delta_dd, Nimage)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    result = fbp_reconstructor.reconstruct_filtered_backprojection(\n",
    "        sorted_images, sorted_angles,\n",
    "        filter_type=filter_type,\n",
    "        filter_size_factor=filter_size_factor,\n",
    "        use_weighting=use_weighting,\n",
    "        chunk_size=25,\n",
    "        use_global_mask=True\n",
    "    )\n",
    "    \n",
    "    reconstruction_time = time.time() - start_time\n",
    "    \n",
    "    # Quick stats\n",
    "    non_zero = np.count_nonzero(result)\n",
    "    coverage = non_zero / result.size * 100\n",
    "    \n",
    "    print(f\"\\nResults:\")\n",
    "    print(f\"  Time: {reconstruction_time:.1f}s\")\n",
    "    print(f\"  Coverage: {coverage:.1f}%\")\n",
    "    print(f\"  Range: {result.min():.6f} to {result.max():.6f}\")\n",
    "    print(f\"  Center: {result[50,50,50]:.6f}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "# rec_small = quick_reconstruction('shepp_logan', 0.25, True)\n",
    "# rec_large = quick_reconstruction('shepp_logan', 0.75, True)\n",
    "# rec_hamming = quick_reconstruction('hamming', 0.5, True)\n",
    "\n",
    "print(\"Use quick_reconstruction() to test different configurations quickly!\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Usage Examples\n\n# Quick test with different configurations\nprint(\"Example usage:\")\nprint(\"=\"*50)\n\nprint(\"\\n1. Quick reconstruction:\")\nprint(\"result = quick_reconstruction('hamming', 0.3, True)\")\n\nprint(\"\\n2. Full control:\")\nprint(\"\"\"fbp = FilteredBackprojectionReconstructor(SOD, delta_dd, Nimage)\nresult = fbp.reconstruct_filtered_backprojection(\n    sorted_images, sorted_angles,\n    filter_type='shepp_logan',      # Filter type\n    filter_size_factor=0.5,         # Filter size\n    use_weighting=True,             # Geometric weighting\n    chunk_size=25,                  # Memory management\n    use_global_mask=True            # Consistent masking\n)\"\"\")\n\nprint(\"\\n3. Available filter types:\")\nfilter_types = ['shepp_logan', 'ram_lak', 'cosine', 'hamming']\nfor ft in filter_types:\n    print(f\"   - {ft}\")\n\nprint(\"\\n4. Recommended filter size factors:\")\nsize_recommendations = [\n    (0.1, \"Very smooth, minimal noise\"),\n    (0.25, \"Smooth, good noise reduction\"),\n    (0.5, \"Balanced detail and noise\"),\n    (0.75, \"High detail, some noise\"),\n    (1.0, \"Maximum detail, more noise\")\n]\n\nfor size, desc in size_recommendations:\n    print(f\"   - {size}: {desc}\")\n\nprint(f\"\\n‚úÖ The reconstruction now gives you full control over filtering!\")\nprint(f\"   Experiment with different combinations to optimize your results.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Summary\n\nThis notebook implements **true filtered backprojection** with the following features:\n\n### ‚úÖ Key Improvements:\n1. **Fixed Shepp-Logan Filter**: Removed the bug that was zeroing out the filter\n2. **True Filtered Backprojection**: Backprojects the filtered projection (not weighted)  \n3. **Configurable Filter Sizes**: Control filter extent with `filter_size_factor` (0.1-1.0)\n4. **Multiple Filter Types**: Shepp-Logan, Ram-Lak, Cosine, Hamming\n5. **Global Mask**: Consistent masking across all projections\n6. **Unrotated Processing**: Clean differential processing without rotation artifacts\n\n### üéõÔ∏è Filter Selection Guide:\n- **Small filters (0.1-0.3)**: Smoother, less noise, may lose details\n- **Medium filters (0.4-0.6)**: Good balance of detail and noise\n- **Large filters (0.7-1.0)**: Maximum detail, potentially more noise\n\n### üîß Filter Types:\n- **Shepp-Logan**: General purpose, good balance\n- **Ram-Lak**: Sharp, preserves high frequencies\n- **Cosine**: Smoother than Ram-Lak, reduces noise\n- **Hamming**: Smoothest, best noise reduction"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}